{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier - Text Classification - Multinomial & Bernoulli\n",
    "\n",
    "In this notebook you will apply the Naive Bayes algorithms for text classification.\n",
    "\n",
    "Your tasks are marked with task numbers (e.g., Task 1). To get full credit you need to complete **ALL** tasks.\n",
    "\n",
    "\n",
    "\n",
    "### Dataset: The 20 Newsgroups data set\n",
    "\n",
    "\n",
    "The 20 newsgroups dataset comprises around 20,000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The 20 newsgroups collection has become a popular data set for experiments in text applications of machine learning techniques, such as text classification and text clustering. The split between the train and test set is based upon a messages posted before and after a specific date.\n",
    "\n",
    "Following is a list of the 20 newsgroups, partitioned (more or less) according to subject matter:\n",
    "\n",
    "- alt.atheism\n",
    "- comp.graphics\n",
    "- comp.os.ms-windows.misc\n",
    "- comp.sys.ibm.pc.hardware\n",
    "- comp.sys.mac.hardware\n",
    "- comp.windows.x\n",
    "- misc.forsale\n",
    "- rec.autos\n",
    "- rec.motorcycles\n",
    "- rec.sport.baseball\n",
    "- rec.sport.hockey\n",
    "- sci.crypt\n",
    "- sci.electronics\n",
    "- sci.med\n",
    "- sci.space\n",
    "- soc.religion.christian\n",
    "- talk.politics.guns\n",
    "- talk.politics.mideast\n",
    "- talk.politics.misc\n",
    "- talk.religion.misc\n",
    "\n",
    "\n",
    "You will normalize the documents, perform preprocessing and vectorize the features. Since the features are categorical, you will implement two different naive Bayes classifiers using Scikit-Learn. \n",
    "- Categorical features (binary valued) are modeled using the Multivariate Bernoulli distrubition \n",
    "- Categorical features (multi-valued) are modeled using the Multinomial distrubition \n",
    "\n",
    "\n",
    "## Steps for Classification:\n",
    "\n",
    "1. Exploratory Data Analysis\n",
    "2. Feature Extraction\n",
    "   - a. Text Normalization (Stemming & Lemmatization)\n",
    "   - b. Text Preprocessing (Tokenization, removing stop words, etc.)\n",
    "   - c. Vectorization of the features\n",
    "3. Model Selection by Hyperparameter Tuning\n",
    "4. Train the Optimal Model\n",
    "5. Analyzing Model Performance\n",
    "6. Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\megha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, precision_recall_curve, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "You will work on a partial dataset with only 4 categories out of the 20 available in the dataset:\n",
    "- alt.atheism\n",
    "- soc.religion.christian\n",
    "- comp.graphics\n",
    "- sci.med\n",
    "\n",
    "\n",
    "The samples are shuffled randomly. This is useful if you wish to select only a subset of samples to quickly train a model and get a first idea of the results before re-training on the complete dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Train and Test Sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'soc.religion.christian','comp.graphics', 'sci.med']\n",
    "\n",
    "train_data = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "X_train = train_data.data\n",
    "y_train = train_data.target\n",
    "\n",
    "\n",
    "test_data = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "X_test = test_data.data\n",
    "y_test = test_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 1. Exploratory Data Analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Check of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Names:  ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']\n",
      "\n",
      "Number of Training Examples:  2257\n",
      "Number of Training Labels:  2257\n",
      "Number of Test Examples:  1502\n",
      "Number of Test Labels:  1502\n",
      "\n",
      "Print a Random Document:\n",
      "\n",
      "From: sd345@city.ac.uk (Michael Collier)\n",
      "Subject: Converting images to HP LaserJet III?\n",
      "Nntp-Posting-Host: hampton\n",
      "Organization: The City University\n",
      "Lines: 14\n",
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "Please email any response.\n",
      "\n",
      "Is this the correct group?\n",
      "\n",
      "Thanks in advance.  Michael.\n",
      "-- \n",
      "Michael Collier (Programmer)                 The Computer Unit,\n",
      "Email: M.P.Collier@uk.ac.city                The City University,\n",
      "Tel: 071 477-8000 x3769                      London,\n",
      "Fax: 071 477-8565                            EC1V 0HB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Names: \", train_data.target_names)\n",
    "\n",
    "print(\"\\nNumber of Training Examples: \", len(X_train))\n",
    "print(\"Number of Training Labels: \", len(y_train))\n",
    "\n",
    "print(\"Number of Test Examples: \",len(X_test))\n",
    "print(\"Number of Test Labels: \", len(y_test))\n",
    "\n",
    "\n",
    "print(\"\\nPrint a Random Document:\\n\")\n",
    "print(X_train[0])\n",
    "#print(y_train[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution\n",
    "\n",
    "#### Task 1: Compute class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: sd345@city.ac.uk (Michael Collier)\\nSubj...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: stanly@grok11.columbiasc.ncr.com (stanly...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  cls\n",
       "0  From: sd345@city.ac.uk (Michael Collier)\\nSubj...    1\n",
       "1  From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\...    1\n",
       "2  From: djohnson@cs.ucsd.edu (Darin Johnson)\\nSu...    3\n",
       "3  From: s0612596@let.rug.nl (M.M. Zwart)\\nSubjec...    3\n",
       "4  From: stanly@grok11.columbiasc.ncr.com (stanly...    3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    X_train[i] = (X_train[i],)\n",
    "df = pd.DataFrame.from_records(X_train, columns = ['text'])\n",
    "#df.info()\n",
    "df.head()\n",
    "df['cls'] = y_train\n",
    "df.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cls</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     text\n",
       "cls      \n",
       "0     480\n",
       "1     584\n",
       "2     594\n",
       "3     599"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('cls').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the Class Distribution\n",
    "\n",
    "\n",
    "#### Task 2: Generate visualization of the class distribution in the following block (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = df.cls.value_counts()\n",
    "plt.figure(figsize = (12,6))\n",
    "sns.barplot(label_counts.index, label_counts.values, alpha = 0.9)\n",
    "\n",
    "plt.xticks(rotation = 'vertical')\n",
    "plt.xlabel('classes', fontsize =12)\n",
    "plt.ylabel('Counts', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## a) Text Normalization by Lemmatization\n",
    "\n",
    "Stemming and Lemmatization are Text Normalization (or sometimes called Word Normalization) techniques in the field of Natural Language Processing that are used to prepare text, words, and documents for further processing.\n",
    "\n",
    "\n",
    "#### Task 3: Lemmatize the training data. You may stem it as well, if it improves the classification accuracy. (10 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()\n",
    "#%%time\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['text_lemmatized'] = df['text'].map(lambda text: ' '.join(lemmatizer.lemmatize(w) for w in nltk.word_tokenize(text.lower())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: mdw33310@uxa.cso.uiuc.edu (Michael D. Walker)\n",
      "Subject: Re: Question about Virgin Mary\n",
      "Organization: University of Illinois at Urbana\n",
      "Lines: 58\n",
      "\n",
      "a.faris@trl.oz.au (Aziz Faris) writes:\n",
      "\n",
      ">Helllo Netters:\n",
      "\n",
      ">I was told the Bible says that God took the body of the Virgin Mary as\n",
      ">she was being carried for burial. Is this true, if so were in the Bible\n",
      ">does it say that.\n",
      "\n",
      ">Regards,\n",
      ">A.Faris\n",
      "\n",
      ">[I think you're talking about the \"assumption of the Blessed Virgin\n",
      ">Mary\".  It says that \"The Immaculate Mother of God, the ever Virgin\n",
      ">Mary, having completed the course of her earthly life, was assumed\n",
      ">body and soul into heavenly glory.\"  This was defined by a Papal\n",
      ">statement in 1950, though it had certainly been believed by some\n",
      ">before that.  Like the Immaculate Conception, this is primarily a\n",
      ">Roman Catholic doctrine, and like it, it has no direct Biblical\n",
      ">support.  Note that Catholics do not believe in \"sola scriptura\".\n",
      ">That is, they do not believe that the Bible is the only source of\n",
      ">Christian knowledge.  Thus the fact that a doctrine has little\n",
      ">Biblical support is not necessarily significant to them.  They believe\n",
      ">that truth can be passed on through traditions of the Church, and also\n",
      ">that it can be revealed to the Church.  I'm not interested in yet\n",
      ">another Catholic/Protestant argument, but if any Catholics can tell us\n",
      ">the basis for these beliefs, I think it would be appropriate.  --clh]\n",
      "\n",
      "\n",
      "\tAgain I find myself wanting to respond to a posting and having neither\n",
      "the time nor the proper materials with me (you would think I would learn my\n",
      "lesson by now--but I'm trying to finish writing my Thesis and don't have tons\n",
      "of time.  Anyway...)\n",
      "\n",
      "\tThe basis for our (the catholic church's) belief in the assumption of\n",
      "Mary, body and soul, into heaven is that, to put it simply, the apostles \n",
      "and all the early generation Christians believed it.  In fact, throughout their\n",
      "ministry the apostles kept in close contact with Mary, and 11 of the 12 were\n",
      "present when she died.  Only Thomas was missing--when he arrived several days\n",
      "later, he asked to be shown her body, and moved with pity, Peter and several of\n",
      "the other apostles brought him to her tomb.  When they arrived the seal was\n",
      "still unbroken.  They broke the seal, entered, and the body was missing.  There\n",
      "was no sign that anyone had entered, forcibly or otherwise, and everything else\n",
      "was laid out exactly as it had been left.  The apostles present all believed\n",
      "that Mary was assumed into heaven--and the apostles TAUGHT this in their  \n",
      "preaching (of course, this does not appear in any of the texts currently \n",
      "considered part of the bible, but it does appear in other writings left behind\n",
      "by several of them.)  Basicaly, as an apostolic church (ie. founded by the\n",
      "apostles), we believe that the teachings of the apostles, whether written down\n",
      "in the bible or written down in other sources, is true, providing that the\n",
      "authenticity of those other sources can be confirmed.  At least in the case of\n",
      "the assumption of Mary, the authenticity is quite clear.\n",
      "\n",
      "\tHope this helps--I would welcome anyone who has more information to\n",
      "\tadd to what I've said.\n",
      "\t\t\t\t\t- Mike Walker\n",
      "\t\t\t\t\t  mdw33310@uxa.cso.uiuc.edu\n",
      "\t\t\t\t\t  (Univ. of Illinois)\n",
      "\t\t\t\t\t  ]\n",
      "\n",
      "\n",
      "Lemmatized Email:\n",
      "\n",
      "from : mdw33310 @ uxa.cso.uiuc.edu ( michael d. walker ) subject : re : question about virgin mary organization : university of illinois at urbana line : 58 a.faris @ trl.oz.au ( aziz faris ) writes : > helllo netters : > i wa told the bible say that god took the body of the virgin mary a > she wa being carried for burial . is this true , if so were in the bible > doe it say that . > regard , > a.faris > [ i think you 're talking about the `` assumption of the blessed virgin > mary '' . it say that `` the immaculate mother of god , the ever virgin > mary , having completed the course of her earthly life , wa assumed > body and soul into heavenly glory . '' this wa defined by a papal > statement in 1950 , though it had certainly been believed by some > before that . like the immaculate conception , this is primarily a > roman catholic doctrine , and like it , it ha no direct biblical > support . note that catholic do not believe in `` sola scriptura '' . > that is , they do not believe that the bible is the only source of > christian knowledge . thus the fact that a doctrine ha little > biblical support is not necessarily significant to them . they believe > that truth can be passed on through tradition of the church , and also > that it can be revealed to the church . i 'm not interested in yet > another catholic/protestant argument , but if any catholic can tell u > the basis for these belief , i think it would be appropriate . -- clh ] again i find myself wanting to respond to a posting and having neither the time nor the proper material with me ( you would think i would learn my lesson by now -- but i 'm trying to finish writing my thesis and do n't have ton of time . anyway ... ) the basis for our ( the catholic church 's ) belief in the assumption of mary , body and soul , into heaven is that , to put it simply , the apostle and all the early generation christian believed it . in fact , throughout their ministry the apostle kept in close contact with mary , and 11 of the 12 were present when she died . only thomas wa missing -- when he arrived several day later , he asked to be shown her body , and moved with pity , peter and several of the other apostle brought him to her tomb . when they arrived the seal wa still unbroken . they broke the seal , entered , and the body wa missing . there wa no sign that anyone had entered , forcibly or otherwise , and everything else wa laid out exactly a it had been left . the apostle present all believed that mary wa assumed into heaven -- and the apostle taught this in their preaching ( of course , this doe not appear in any of the text currently considered part of the bible , but it doe appear in other writing left behind by several of them . ) basicaly , a an apostolic church ( ie . founded by the apostle ) , we believe that the teaching of the apostle , whether written down in the bible or written down in other source , is true , providing that the authenticity of those other source can be confirmed . at least in the case of the assumption of mary , the authenticity is quite clear . hope this help -- i would welcome anyone who ha more information to add to what i 've said . - mike walker mdw33310 @ uxa.cso.uiuc.edu ( univ . of illinois ) ]\n"
     ]
    }
   ],
   "source": [
    "print(df['text'][171])\n",
    "print(\"\\nLemmatized Email:\\n\")\n",
    "print(df['text_lemmatized'][171])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 2. Feature Extraction </font>\n",
    "\n",
    "## b) Text Preprocessing & c) Feature Vectorization\n",
    "\n",
    "We can combine text preprocessing, feature vectorization and model training using the sklearn Pipeline object. This Pipeline object can be used for model selection and for training the optimal model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue> 3. Model Selection </font>\n",
    "\n",
    "\n",
    "There are no hyperparameters in a NB model except the Laplace smoothing parameter alpha.\n",
    "\n",
    "However, there are multiple hyperparameters for the CountVectorizer() and TfidfTransformer(). We need to select the best model based on the optimal values of these hyperparameters. This process is called hyper-parameter tuning.\n",
    "\n",
    "For hyperparameter tuning, we will build a compund classifier using the sklearn Pipeline class. It will combine the CountVectorizer(), TfidfTransformer() and MultinomialNB() objects and will create a single object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Pipeline for Hyperparameter Tuning\n",
    "\n",
    "\n",
    "#### Task 4: Build a Pipeline object by combining CountVectorizer() and MultinomialNB() (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_multinomialNB = Pipeline([\n",
    "        ('vect', CountVectorizer()),\n",
    "#         ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "#### Task 5: Perform hyperparamer tuning for the following hyperparameters: (5 pts)\n",
    "- CountVectorizer()\n",
    "         -- ngram_range\n",
    "         -- stop_words\n",
    "- MultinomialNB()\n",
    "        -- alpha\n",
    "        \n",
    "## **<font color=red size=5>Important:</font>**\n",
    "\n",
    "The GridSearchCV takes an argument to define the scoring metric (performance measure). \n",
    "\n",
    "See the list of possible scoring functions:\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "For multiclass classification, we may use \"f1_micro\" scoring function. The f1_micro function is the average of the F1 score of each class with weighting depending on the average parameter.\n",
    "\n",
    "The macro-average (\"f1_macro\") will compute the metric independently for each class and then take the average (hence treating all classes equally), whereas a micro-average (\"f1_micro\") will aggregate the contributions of all classes to compute the average metric. In a multi-class classification setup, micro-average is preferable if you suspect there might be class imbalance (i.e you may have many more examples of one class than of other classes).\n",
    "\n",
    "In the binary classification, \"f1\" score function can be used. We may also use the precision_score, recall_score, roc_auc_score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Score: 0.980505\n",
      "\n",
      "Optimal Hyperparameter Values: \n",
      "clf__alpha: 0.1\n",
      "vect__ngram_range: (1, 2)\n",
      "vect__stop_words: 'english'\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "param_grid = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'vect__stop_words': ['english', None],\n",
    "#    'vect__binary': [True, False],\n",
    "    'clf__alpha': [0.1, 1.0, 1.5, 1.8]\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "#     'tfidf__norm': ('l1', 'l2'),\n",
    "}\n",
    "\n",
    "clf_multinomial_cv = GridSearchCV(text_clf_multinomialNB, param_grid, scoring='f1_micro', cv=5)\n",
    "\n",
    "clf_multinomial_cv = clf_multinomial_cv.fit(df.text_lemmatized, y_train)\n",
    "\n",
    "\n",
    "print(\"\\nBest Score: %f\" % clf_multinomial_cv.best_score_)\n",
    "\n",
    "print(\"\\nOptimal Hyperparameter Values: \")\n",
    "\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"%s: %r\" % (param_name, clf_multinomial_cv.best_params_[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 4. Train the Optimal Multinomial Model </font>\n",
    "\n",
    "#### Task 6: Using the optimal hyperparameter values, create the optimal model. Then, fit the model. (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 2), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 2), binary=False)),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "multinomialNB_clf.fit(df.text_lemmatized, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> 6. Evaluate the Model on Test Data </font>\n",
    "\n",
    "#### Task 7:  Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report\n",
    "\n",
    "\n",
    "### Note: For multi-class classification, set the \"average\" attribute to \"micro\" for the following functions:\n",
    "- precision_score\n",
    "- recall_score\n",
    "- f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[298   4   5  12]\n",
      " [  6 376   5   2]\n",
      " [  7  23 358   8]\n",
      " [  5   4   4 385]]\n",
      "\n",
      "Test Precision = 0.943409\n",
      "Test Recall = 0.943409\n",
      "Test F1 Score = 0.943409\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.94      0.93      0.94       319\n",
      "         comp.graphics       0.92      0.97      0.94       389\n",
      "               sci.med       0.96      0.90      0.93       396\n",
      "soc.religion.christian       0.95      0.97      0.96       398\n",
      "\n",
      "             micro avg       0.94      0.94      0.94      1502\n",
      "             macro avg       0.94      0.94      0.94      1502\n",
      "          weighted avg       0.94      0.94      0.94      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = multinomialNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average= \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average= \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average= \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multinomial NB: TF-IDF Model\n",
    "\n",
    "#### Task 8: Implement the Multinomial model using the TF-IDF feature vectors (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer(), TfidfTransformer() and MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        ...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multinomialNB_clf_tfidf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 1), binary=False)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultinomialNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "multinomialNB_clf_tfidf.fit(df.text_lemmatized, df.cls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "#### Task 9: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[277   3   8  31]\n",
      " [  5 377   1   6]\n",
      " [  4  20 359  13]\n",
      " [  4   3   3 388]]\n",
      "\n",
      "Test Precision = 0.932756\n",
      "Test Recall = 0.932756\n",
      "Test F1 Score = 0.932756\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.96      0.87      0.91       319\n",
      "         comp.graphics       0.94      0.97      0.95       389\n",
      "               sci.med       0.97      0.91      0.94       396\n",
      "soc.religion.christian       0.89      0.97      0.93       398\n",
      "\n",
      "             micro avg       0.93      0.93      0.93      1502\n",
      "             macro avg       0.94      0.93      0.93      1502\n",
      "          weighted avg       0.93      0.93      0.93      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = multinomialNB_clf_tfidf.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multinomial Model With TF-IDF Feature Vectors </font>\n",
    "\n",
    "We observe that both precision and recall decrease with TF-IDF feature vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Multivariate Bernoulli NB\n",
    "\n",
    "#### Task 10: Implement the Multivariate Bernoulli Model (10 pts)\n",
    "- Build a Pipeline object by combining CountVectorizer() and BernoulliNB()\n",
    "\n",
    "### <font color=red> Note: </font>\n",
    "The \"binary\" attribute of the CountVectorizer() object should be set to \"True\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('clf', BernoulliNB(alpha=0.1, binarize=0.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bernoulliNB_clf = Pipeline([\n",
    "        ('vect', CountVectorizer(stop_words='english', ngram_range=(1, 1), binary=True)),\n",
    "        ('clf', BernoulliNB(alpha=0.1)),\n",
    "    ])\n",
    "\n",
    "bernoulliNB_clf.fit(df.text_lemmatized, df.cls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model on Test Data \n",
    "\n",
    "\n",
    "#### Task 11: Evaluate the model on test data and generate (10 pts)\n",
    "- Confusion Matrix\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 score\n",
    "- Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Confusion Matrix:\n",
      "[[286  12   7  14]\n",
      " [  6 381   2   0]\n",
      " [  4  83 308   1]\n",
      " [  5  36   2 355]]\n",
      "\n",
      "Test Precision = 0.885486\n",
      "Test Recall = 0.885486\n",
      "Test F1 Score = 0.885486\n",
      "\n",
      "Classification Report:\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "           alt.atheism       0.95      0.90      0.92       319\n",
      "         comp.graphics       0.74      0.98      0.85       389\n",
      "               sci.med       0.97      0.78      0.86       396\n",
      "soc.religion.christian       0.96      0.89      0.92       398\n",
      "\n",
      "             micro avg       0.89      0.89      0.89      1502\n",
      "             macro avg       0.90      0.89      0.89      1502\n",
      "          weighted avg       0.90      0.89      0.89      1502\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_predicted = bernoulliNB_clf.predict(X_test)\n",
    "\n",
    "print(\"\\nTest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_predicted))\n",
    "\n",
    "\n",
    "precision_test = precision_score(y_test, y_test_predicted, average = \"micro\") \n",
    "print(\"\\nTest Precision = %f\" % precision_test)\n",
    "\n",
    "\n",
    "recall_test = recall_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test Recall = %f\" % recall_test)\n",
    "\n",
    "\n",
    "f1_test = f1_score(y_test, y_test_predicted, average = \"micro\")\n",
    "print(\"Test F1 Score = %f\" % f1_test)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_predicted, target_names = ['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=maroon> Observation on Multivariate Bernoulli Model </font>\n",
    "\n",
    "#### Task 12: Write a short account of your observation on the following aspects of your experimentation with 3 NB classifiers (10 pts):\n",
    "- Impact of data normalization technique (did you observe performance improvement with lemmatization and/or stemming)\n",
    "Interestingly, the best score value while doing hyperparameter tuning is better for normal text than the lemmatized text. Also, in the first model multinomialNB_clf, both lemmatized and normal text had the same values for precision, recall and F1 score. However, when the Multinomial NB: TF-IDF Model is used, lemmatized text showed a better performance than the normal text.\n",
    "- Which classifier gave the best precision? Best recall? Best F1 Score? Explain their performance variance.\n",
    "Multinomial NB gave the best values. Precision : 0.943409, Recall : 0.943409, F1 Score : 0.943409\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
